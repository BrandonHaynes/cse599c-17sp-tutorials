{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Neural Art Style Transfer\n",
    "=============\n",
    "\n",
    "This demo is adapted from [neuralart_tensorflow](https://github.com/ckmarkoh/neuralart_tensorflow) and [this paper review](https://github.com/tensorflow/magenta/blob/master/magenta/reviews/styletransfer.md).\n",
    "\n",
    "In late August 2015, Gatys et al. from The University of TÃ¼bingen published [A Neural Algorithm of Artistic Style](http://arxiv.org/pdf/1508.06576v2.pdf). It demonstrated a way to present one piece of artwork in the style of a separate piece. \n",
    "\n",
    "\n",
    "The model is built on top of a deep conv net: **VGG19**, which is used in the ImageNet Large-Scale Visual Recognition Challenge (ILSVRC). VGG19 is trained on more than a million images and can classify images into 1000 object categories.\n",
    "\n",
    "This demo requires a copy of the [pretrained VGG19 model data](https://drive.google.com/file/d/0B8QJdgMvQDrVU2cyZjFKU1RrLUU/view?usp=sharing) in the same directory. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "IMAGE_W = 400 \n",
    "IMAGE_H = 300 \n",
    "OUTOUT_DIR = './results'\n",
    "\n",
    "MEAN_VALUES = np.array([123, 117, 104]).reshape((1,1,1,3))  # RGB means\n",
    "\n",
    "def read_image(path):\n",
    "  image = scipy.misc.imread(path)\n",
    "  image = image[np.newaxis,:IMAGE_H,:IMAGE_W,:] \n",
    "  image = image - MEAN_VALUES\n",
    "  return image\n",
    "\n",
    "def write_image(path, image):\n",
    "  image = image + MEAN_VALUES\n",
    "  image = image[0]\n",
    "  image = np.clip(image, 0, 255).astype('uint8')\n",
    "  scipy.misc.imsave(path, image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_net(ntype, nin, nwb=None):\n",
    "  if ntype == 'conv':\n",
    "    return tf.nn.relu(tf.nn.conv2d(nin, nwb[0], strides=[1, 1, 1, 1], padding='SAME')+ nwb[1])\n",
    "  elif ntype == 'pool':\n",
    "    return tf.nn.avg_pool(nin, ksize=[1, 2, 2, 1],\n",
    "                  strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def get_weight_bias(vgg_layers, i,):\n",
    "  weights = vgg_layers[i][0][0][0][0][0]\n",
    "  weights = tf.constant(weights)\n",
    "  bias = vgg_layers[i][0][0][0][0][1]\n",
    "  bias = tf.constant(np.reshape(bias, (bias.size)))\n",
    "  return weights, bias\n",
    "\n",
    "def build_vgg19(path):\n",
    "  net = {}\n",
    "  vgg_rawnet = scipy.io.loadmat(path)\n",
    "  vgg_layers = vgg_rawnet['layers'][0]\n",
    "  net['input'] = tf.Variable(np.zeros((1, IMAGE_H, IMAGE_W, 3)).astype('float32'))\n",
    "  net['conv1_1'] = build_net('conv',net['input'],get_weight_bias(vgg_layers,0))\n",
    "  net['conv1_2'] = build_net('conv',net['conv1_1'],get_weight_bias(vgg_layers,2))\n",
    "  net['pool1']   = build_net('pool',net['conv1_2'])\n",
    "  net['conv2_1'] = build_net('conv',net['pool1'],get_weight_bias(vgg_layers,5))\n",
    "  net['conv2_2'] = build_net('conv',net['conv2_1'],get_weight_bias(vgg_layers,7))\n",
    "  net['pool2']   = build_net('pool',net['conv2_2'])\n",
    "  net['conv3_1'] = build_net('conv',net['pool2'],get_weight_bias(vgg_layers,10))\n",
    "  net['conv3_2'] = build_net('conv',net['conv3_1'],get_weight_bias(vgg_layers,12))\n",
    "  net['conv3_3'] = build_net('conv',net['conv3_2'],get_weight_bias(vgg_layers,14))\n",
    "  net['conv3_4'] = build_net('conv',net['conv3_3'],get_weight_bias(vgg_layers,16))\n",
    "  net['pool3']   = build_net('pool',net['conv3_4'])\n",
    "  net['conv4_1'] = build_net('conv',net['pool3'],get_weight_bias(vgg_layers,19))\n",
    "  net['conv4_2'] = build_net('conv',net['conv4_1'],get_weight_bias(vgg_layers,21))\n",
    "  net['conv4_3'] = build_net('conv',net['conv4_2'],get_weight_bias(vgg_layers,23))\n",
    "  net['conv4_4'] = build_net('conv',net['conv4_3'],get_weight_bias(vgg_layers,25))\n",
    "  net['pool4']   = build_net('pool',net['conv4_4'])\n",
    "  net['conv5_1'] = build_net('conv',net['pool4'],get_weight_bias(vgg_layers,28))\n",
    "  net['conv5_2'] = build_net('conv',net['conv5_1'],get_weight_bias(vgg_layers,30))\n",
    "  net['conv5_3'] = build_net('conv',net['conv5_2'],get_weight_bias(vgg_layers,32))\n",
    "  net['conv5_4'] = build_net('conv',net['conv5_3'],get_weight_bias(vgg_layers,34))\n",
    "  net['pool5']   = build_net('pool',net['conv5_4'])\n",
    "  return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_content_loss(p, x):\n",
    "  M = p.shape[1]*p.shape[2]\n",
    "  N = p.shape[3]\n",
    "  loss = (1./(2* N**0.5 * M**0.5 )) * tf.reduce_sum(tf.pow((x - p),2))  \n",
    "  return loss\n",
    "\n",
    "\n",
    "def gram_matrix(x, area, depth):\n",
    "  x1 = tf.reshape(x,(area,depth))\n",
    "  g = tf.matmul(tf.transpose(x1), x1)\n",
    "  return g\n",
    "\n",
    "def gram_matrix_val(x, area, depth):\n",
    "  x1 = x.reshape(area,depth)\n",
    "  g = np.dot(x1.T, x1)\n",
    "  return g\n",
    "\n",
    "def build_style_loss(a, x):\n",
    "  M = a.shape[1]*a.shape[2]\n",
    "  N = a.shape[3]\n",
    "  A = gram_matrix_val(a, M, N )\n",
    "  G = gram_matrix(x, M, N )\n",
    "  loss = (1./(4 * N**2 * M**2)) * tf.reduce_sum(tf.pow((G - A),2))\n",
    "  return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "VGG_MODEL = 'imagenet-vgg-verydeep-19.mat'  # pretrained deep conv net model\n",
    "INI_NOISE_RATIO = 0.7\n",
    "STYLE_STRENGTH = 300  # How to interpolate between the content and the style\n",
    "ITERATION = 2000\n",
    "\n",
    "CONTENT_LAYERS =[('conv4_2',1.)]\n",
    "STYLE_LAYERS=[('conv1_1',1.),('conv2_1',1.),('conv3_1',1.),('conv4_1',1.),('conv5_1',1.)]\n",
    "\n",
    "def stylize(content, style):\n",
    "  net = build_vgg19(VGG_MODEL)\n",
    "  sess = tf.Session()\n",
    "  sess.run(tf.initialize_all_variables())\n",
    "  noise_img = np.random.uniform(-20, 20, (1, IMAGE_H, IMAGE_W, 3)).astype('float32')\n",
    "  content_img = read_image(content)\n",
    "  style_img = read_image(style)\n",
    "\n",
    "  sess.run([net['input'].assign(content_img)])\n",
    "  cost_content = sum(map(lambda l,: l[1]*build_content_loss(sess.run(net[l[0]]) ,  net[l[0]])\n",
    "    , CONTENT_LAYERS))\n",
    "\n",
    "  sess.run([net['input'].assign(style_img)])\n",
    "  cost_style = sum(map(lambda l: l[1]*build_style_loss(sess.run(net[l[0]]) ,  net[l[0]])\n",
    "    , STYLE_LAYERS))\n",
    "\n",
    "  \n",
    "  # Minimizing a combination of content loss and style loss\n",
    "  cost_total = cost_content + STYLE_STRENGTH * cost_style\n",
    "  optimizer = tf.train.AdamOptimizer(2.0)\n",
    "\n",
    "  train = optimizer.minimize(cost_total)\n",
    "  sess.run(tf.initialize_all_variables())\n",
    "  sess.run(net['input'].assign( INI_NOISE_RATIO * noise_img + (1.-INI_NOISE_RATIO) * content_img))\n",
    "\n",
    "  if not os.path.exists(OUTOUT_DIR):\n",
    "      os.mkdir(OUTOUT_DIR)\n",
    "\n",
    "  for i in range(ITERATION):\n",
    "    sess.run(train)\n",
    "    if i % 100 == 0:\n",
    "      result_img = sess.run(net['input'])\n",
    "      print(sess.run(cost_total))\n",
    "      write_image(os.path.join(OUTOUT_DIR,'%s.png'%(str(i).zfill(4))),result_img)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-9194a36c16fd>:12: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "WARNING:tensorflow:From <ipython-input-8-9194a36c16fd>:31: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "2.01626e+11\n",
      "2.70734e+09\n",
      "1.1101e+09\n",
      "6.47858e+08\n",
      "4.55945e+08\n",
      "3.56306e+08\n",
      "2.944e+08\n",
      "2.52124e+08\n",
      "2.20999e+08\n",
      "1.9719e+08\n",
      "1.78687e+08\n",
      "1.64048e+08\n"
     ]
    }
   ],
   "source": [
    "stylize(content=\"images/Quad.jpg\", style=\"images/StarryNight.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Original<img src=\"images/Quad.jpg\"/>\n",
    "0<img src=\"results/0000.png\"/>\n",
    "100<img src=\"results/0100.png\"/>\n",
    "200<img src=\"results/0200.png\"/>\n",
    "500<img src=\"results/0500.png\"/>\n",
    "1000<img src=\"results/1000.png\"/>\n",
    "1500<img src=\"results/1500.png\"/>\n",
    "2000<img src=\"results/2000.png\"/>\n",
    "3000<img src=\"results/3000.png\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
